{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import chess\n",
        "\n",
        "# Load white and black datasets\n",
        "white_df = pd.read_csv(\"white_df_100.csv\")\n",
        "black_df = pd.read_csv(\"black_df_100.csv\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pre-process Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Concatenate the data\n",
        "all_df = pd.concat([black_df, white_df])\n",
        "\n",
        "# Pre-process data\n",
        "all_df['Is_Check'] = all_df['Is_Check'].astype(int)\n",
        "all_df['Is_Capture'] = all_df['Piece_Captured'].apply(lambda x: 1 if x != None else 0)\n",
        "all_df = all_df.drop(columns=['FEN'])\n",
        "\n",
        "# Save the combined dataset to a file\n",
        "all_df.to_csv('all_df_100.csv', index=False)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Define Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ast\n",
        "\n",
        "# Define helper functions for converting chess moves to tuples and vice versa\n",
        "def chess_square_to_number(square: str) -> int:\n",
        "    file = square[0]\n",
        "    rank = int(square[1])\n",
        "    file_dict = {'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8}\n",
        "    return (file_dict[file] - 1) * 8 + rank\n",
        "\n",
        "def chess_move_to_tuple(move):\n",
        "    start_square = chess_square_to_number(move[:2])\n",
        "    end_square = chess_square_to_number(move[2:])\n",
        "    return (start_square, end_square)\n",
        "\n",
        "def chess_moves_to_tuples(moves):\n",
        "    result = []\n",
        "    for move in moves:\n",
        "        result.append(chess_move_to_tuple(move))\n",
        "    return result\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Convert Moves to Tuples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert moves to tuples\n",
        "all_df[\"Move\"] = all_df[\"Move\"].apply(lambda x: chess_move_to_tuple(x))\n",
        "all_df[\"Top_10_Moves\"] = all_df[\"Top_10_Moves\"].apply(lambda x: ast.literal_eval(x))\n",
        "all_df[\"Top_10_Moves\"] = all_df[\"Top_10_Moves\"].apply(lambda x: chess_moves_to_tuples(x))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prepare Data for Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for model training\n",
        "candidate_data = all_df[\"Top_10_Moves\"].tolist()\n",
        "target_data = all_df[\"Move\"].tolist()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Calculate Euclidean Distances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate the Euclidean distance between each candidate move and the target move\n",
        "X, y = [], []\n",
        "for i, candidates in enumerate(candidate_data):\n",
        "    target = target_data[i]\n",
        "    for candidate in candidates:\n",
        "        X.append(candidate)\n",
        "        y.append(np.linalg.norm(np.array(candidate) - np.array(target)))\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestRegressor(random_state=42)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Train the model\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Define Helper Functions for Sorting Candidates and Calculating Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def sort_candidates(candidates):\n",
        "    likelihoods = model.predict(candidates)\n",
        "    return sorted(candidates, key=lambda x: likelihoods[candidates.index(x)], reverse=True)\n",
        "\n",
        "def get_top_candidate(candidates):\n",
        "    likelihoods = model.predict(candidates)\n",
        "    sorted_candidates = sorted(candidates, key=lambda x: likelihoods[candidates.index(x)], reverse=False)\n",
        "    return sorted_candidates[0]\n",
        "\n",
        "def get_random_candidate(candidates):\n",
        "    return random.choice(candidates)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Calculate Model Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pure Accuracy: 0.237831701433234\n"
          ]
        }
      ],
      "source": [
        "# Calculate the accuracy of the model by comparing the top predicted move to the target move\n",
        "correct = sum(get_top_candidate(candidates) == target for candidates, target in zip(candidate_data, target_data))\n",
        "total = len(candidate_data)\n",
        "accuracy = correct / total\n",
        "print(\"Pure Accuracy:\", accuracy)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Calculate Random Selection Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Selection Accuracy: 0.11338158081453101\n"
          ]
        }
      ],
      "source": [
        "# Calculate the accuracy of randomly selecting a move from the candidates\n",
        "random_correct = sum(get_random_candidate(candidates) == target for candidates, target in zip(candidate_data, target_data))\n",
        "random_accuracy = random_correct / total\n",
        "print(\"Random Selection Accuracy:\", random_accuracy)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Compare Accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trained Model Pure Accuracy: 0.237831701433234\n",
            "Random Selection Accuracy: 0.11338158081453101\n"
          ]
        }
      ],
      "source": [
        "print(\"Trained Model Pure Accuracy:\", accuracy)\n",
        "print(\"Random Selection Accuracy:\", random_accuracy)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['final_model_chess.joblib']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "# Save the model to a file\n",
        "joblib.dump(model, 'final_model_chess.joblib')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
